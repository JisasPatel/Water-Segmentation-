You can copyâ€“paste directly into **README.md**.

---

# ğŸš€ **Dual-Stage Kalman Framework for Water-Body Segmentation**

### *Spatial Denoising + Temporal Prediction using Deep Learning + Kalman Filtering*

---

## ğŸ“Œ **Overview**

This repository contains the implementation of a **Dual-Stage Kalman Framework** for accurate and lightweight water-body extraction from satellite imagery.
The system integrates:

### **ğŸ”¹ Module 1 â€” LKF-SegNet (Spatial Segmentation Engine)**

* U-Net decoder
* MobileNetV2 lightweight encoder
* **Spatial Learnable Kalman Filter (LKF)** at the bottleneck
* **Edge-Weighted Loss** for sharp waterâ€“land boundaries

### **ğŸ”¹ Module 2 â€” Temporal Kalman Filter (TKF)**

* Applied on sequences of probability maps
* Handles synthetic video generated via sliding-window
* Produces smoothed and **one-step-ahead predicted masks**

This hybrid deep-learning + signal-processing approach improves **spatial coherence**, **temporal stability**, and **prediction capability** while remaining computationally efficient for edge devices (drones, IoT, etc.).

---

## ğŸ“‚ **Repository Structure**

```
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ lkf_segnet.py            # Full LKF-SegNet implementation
â”‚   â”œâ”€â”€ kalman_filter_spatial.py # Learnable Spatial Kalman Filter module
â”‚   â”œâ”€â”€ kalman_filter_temporal.py# Temporal Kalman Filter implementation
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_lkf_segnet.py      # Training loop with edge-weighted loss
â”‚   â”œâ”€â”€ loss_edge_weighted.py    # Canny + distance-transform loss
â”‚
â”œâ”€â”€ synthetic_video/
â”‚   â”œâ”€â”€ generate_synthetic_video.py
â”‚   â”œâ”€â”€ run_temporal_filter.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ dataset_loader.py
â”‚   â”œâ”€â”€ augmentation.py
â”‚   â”œâ”€â”€ metrics.py
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ mae_plot.png
â”‚   â”œâ”€â”€ iou_distribution.png
â”‚   â”œâ”€â”€ train_vs_test_metrics.png
â”‚   â”œâ”€â”€ qualitative_segmentation.png
â”‚   â”œâ”€â”€ temporal_outputs.png
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§  **Model Architecture**

### ğŸ”· **LKF-SegNet Overview**

*(Insert your image here in GitHub)*

```
![LKF-SegNet Architecture](images/lkf_segnet_architecture.png)
```

A U-Netâ€“style encoderâ€“decoder network enhanced with a **Spatial Learnable Kalman Filter** to stabilize and denoise feature maps.

---

### ğŸ”· **Row-Wise Learnable Kalman Filtering**

```
![Row-wise LKF](images/lkf_internal_flow.png)
```

Each row of the bottleneck feature map is treated as a pseudo-temporal sequence, enabling recursive predictionâ€“correction at the feature level.

---

## ğŸ“¦ **Dataset Preparation**

* Images resized to **256Ã—256**
* Binary masks (1 = water, 0 = non-water)
* Augmentations used:

  * Horizontal/vertical flips
  * Color normalization
  * Random cropping

### **Synthetic Video Generation**

A sliding window is used to create an ordered sequence of overlapping patches from a single large satellite image:

```
python generate_synthetic_video.py --image path/to/image.png
```

---

## ğŸ”§ **Installation**

```bash
git clone https://github.com/yourusername/dual-stage-kalman-water-body-segmentation
cd dual-stage-kalman-water-body-segmentation
pip install -r requirements.txt
```

---

## ğŸ‹ï¸ **Training LKF-SegNet**

```bash
python train_lkf_segnet.py \
    --dataset path/to/dataset \
    --epochs 50 \
    --batch_size 8
```

Training uses:

* MobileNetV2 encoder
* Edge-Weighted Loss
* Spatial Learnable Kalman Filter

---

## ğŸ¬ **Run Temporal Kalman Filtering**

```bash
python run_temporal_filter.py --input_folder synthetic_video/
```

Outputs:
âœ” Smoothed masks
âœ” One-step-ahead predictions
âœ” MAE plots

---

## ğŸ“Š **Results**

### **1ï¸âƒ£ MAE Over Time (First 50 Frames)**

Shows temporal behavior of:

* Observation ( z_t )
* Filtered state ( x_t )
* Predicted state ( x_{t|t-1} )

The filter reduces flicker and stabilizes predictions.

```
![MAE Plot](results/mae_plot.png)
```

---

### **2ï¸âƒ£ Temporal Filtering Example**

For one frame:

* RGB patch
* Ground Truth
* Observation
* Filtered output
* Predicted output

```
![Temporal Outputs](results/temporal_outputs.png)
```

The filter smooths noise and creates stable predictions.

---

### **3ï¸âƒ£ Train vs Test Metrics**

```
![Train vs Test](results/train_vs_test_metrics.png)
```

High generalization:

* Accuracy â‰ˆ 89%
* IoU â‰ˆ 75%
* Precision â‰ˆ 89%
* Recall â‰ˆ 83%

---

### **4ï¸âƒ£ IoU Distribution**

```
![IoU Distribution](results/iou_distribution.png)
```

Most IoUs lie within **0.70â€“0.90**, indicating consistent segmentation performance.

---

### **5ï¸âƒ£ Qualitative Segmentation**

```
![Qualitative](results/qualitative_segmentation.png)
```

The model preserves boundary sharpness and captures water regions accurately.

---

## ğŸš€ **Key Contributions**

âœ” A **lightweight** MobileNetV2-based segmentation model
âœ” Integration of **Spatial Learnable Kalman Filtering**
âœ” **Edge-Weighted Loss** for crisp water boundaries
âœ” **Synthetic temporal dataset** to evaluate temporal filtering
âœ” Temporal Kalman Filter enabling **prediction + smoothing**
âœ” Detailed experiments demonstrating improvement over raw CNN outputs

---

## ğŸ“š **Citation**

If you use this work, please cite:

```
@article{your_kalman_2025,
  title={Dual-Stage Kalman Framework for Spatial and Temporal Water-Body Segmentation},
  author={Your Name},
  year={2025}
}
```
---

## ğŸ¤ **Contributions**

Pull requests are welcome!
If you find issues, open an issue with screenshots and logs.
